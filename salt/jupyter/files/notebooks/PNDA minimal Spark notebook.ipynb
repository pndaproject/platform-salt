{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "println(\"Spark version : \" + sc.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "case class Employee(name: String, age: Int)\n",
    "\n",
    "val df = sc.parallelize(Seq(\n",
    "        Employee(\"Jack Smith\", 32),\n",
    "        Employee(\"Emilia Roberts\", 28),\n",
    "        Employee(\"Peter Williams\", 25),\n",
    "        Employee(\"Sarah Jackson\", 33),\n",
    "        Employee(\"Billy Johns\", 40)\n",
    "        )).toDF()\n",
    "\n",
    "\n",
    "df.registerTempTable(\"employees\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%sql\n",
    "SELECT * FROM employees WHERE age > 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// Pi Estimation\n",
    "var samples = 500\n",
    "val count = sc.parallelize(1 to samples).filter { _ =>\n",
    "  val x = math.random\n",
    "  val y = math.random\n",
    "  x*x + y*y < 1\n",
    "}.count()\n",
    "println(s\"Pi is roughly ${4.0 * count / samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "//Sorting of list of numbers\n",
    "val arr_sort = sc.parallelize(List.fill(100)(100).map(scala.util.Random.nextInt))\n",
    "arr_sort.sortBy(c => c, true).collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "//Count by Value\n",
    "val c = sc.parallelize(List.fill(50)(50).map(scala.util.Random.nextInt))\n",
    "c.countByValue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  },
  "widgets": {
   "state": {
    "4c7faa99644f4ea09db718f0e1c25167": {
     "views": [
      {
       "cell_index": 2
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
